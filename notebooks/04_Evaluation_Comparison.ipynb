{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04_Evaluation_Comparison — Evaluación y comparación\n",
        "\n",
        "- Inferencia en test para los 3 enfoques.\n",
        "- Métricas: Exact Match por campo (macro), % validación contable, F1 (si aplica), latencia/doc, tamaño modelo, facilidad despliegue (0–5).\n",
        "- Selección del ganador con score:\n",
        "  score = 0.6*ExactMatchPromedio + 0.2*ValidaciónContable - 0.1*LatenciaZ - 0.1*TamañoZ\n",
        "- Guardar CSV y PDF en `model/reports/` y errores en JSON.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(            name  em_macro  accounting_pct  latency_s  size_mb  deploy_ease  \\\n",
              " 0  Paddle+Reglas  0.142857             0.0   0.000260       50            5   \n",
              " 1          Donut  0.142857             0.0   0.000063      400            2   \n",
              " 2     LayoutLMv3  0.142857             0.0   0.000000      450            2   \n",
              " \n",
              "       lat_z    size_z     score  \n",
              " 0  1.376268 -1.404879  0.088575  \n",
              " 1 -0.406329  0.561951  0.070152  \n",
              " 2 -0.969940  0.842927  0.098416  ,\n",
              " {'best_model': 'LayoutLMv3',\n",
              "  'metrics': {'name': 'LayoutLMv3',\n",
              "   'em_macro': 0.14285714285714285,\n",
              "   'accounting_pct': 0.0,\n",
              "   'latency_s': 0.0,\n",
              "   'size_mb': 450,\n",
              "   'deploy_ease': 2,\n",
              "   'lat_z': -0.9699396886474567,\n",
              "   'size_z': 0.8429272304235246,\n",
              "   'score': 0.09841553153667892}})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os, re, json, time, random\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "from pathlib import Path\n",
        "\n",
        "random.seed(42); np.random.seed(42)\n",
        "ROOT = Path(os.getcwd())\n",
        "# Normalizar raíz para evitar notebooks/data si se ejecuta desde notebooks/\n",
        "if (ROOT.name == 'notebooks') and (ROOT.parent / 'data').exists():\n",
        "    ROOT = ROOT.parent\n",
        "else:\n",
        "    for p in [ROOT] + list(ROOT.parents):\n",
        "        if (p / 'data').exists():\n",
        "            ROOT = p\n",
        "            break\n",
        "DATA = ROOT / 'data'\n",
        "MODEL = ROOT / 'model'\n",
        "REPORTS = MODEL / 'reports'\n",
        "OCR_DIR = DATA / 'ocr'\n",
        "SPLITS = DATA / 'splits'\n",
        "GT_DIR = DATA / 'gt'\n",
        "\n",
        "REPORTS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def load_ids(name):\n",
        "    return [x.strip() for x in (SPLITS/f'{name}.txt').read_text(encoding='utf-8').splitlines() if x.strip()]\n",
        "\n",
        "def read_gt(doc_id):\n",
        "    p = GT_DIR / f'{doc_id}.json'\n",
        "    with open(p,'r',encoding='utf-8') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def normalize_money(x):\n",
        "    if x is None: return None\n",
        "    if isinstance(x,(int,float)): return float(x)\n",
        "    s = str(x).strip().replace(' ', '')\n",
        "    s = s.replace('.', '').replace(',', '.') if s.count(',')==1 and s.count('.')>1 else s\n",
        "    s = re.sub(r'[^0-9\\.-]', '', s)\n",
        "    try: return float(s)\n",
        "    except: return None\n",
        "\n",
        "def exact_match(a,b):\n",
        "    return 1.0 if (a==b) else 0.0\n",
        "\n",
        "# Heurística baseline basada en OCR+reglas (y clasificador si existe)\n",
        "\n",
        "def heuristic_extract(doc_id):\n",
        "    ocr_path = OCR_DIR / f'{doc_id}.json'\n",
        "    if not ocr_path.exists():\n",
        "        return {}\n",
        "    with open(ocr_path,'r',encoding='utf-8') as f:\n",
        "        doc = json.load(f)\n",
        "    lines = []\n",
        "    for page in doc.get('pages', []):\n",
        "        for ln in page.get('lines', []):\n",
        "            t = ln.get('text','')\n",
        "            if t: lines.append(t)\n",
        "    text = '\\n'.join(lines)\n",
        "\n",
        "    # Reglas simples\n",
        "    fecha = None\n",
        "    m = re.search(r'(\\d{4}[-/.]\\d{2}[-/.]\\d{2})', text)\n",
        "    if m: fecha = m.group(1).replace('/', '-').replace('.', '-')\n",
        "\n",
        "    nit = None\n",
        "    m = re.search(r'(\\d{6,10}[-–]\\d)', text)\n",
        "    if m: nit = m.group(1).replace('–','-')\n",
        "\n",
        "    def find_value_after(keyword):\n",
        "        for ln in lines:\n",
        "            if keyword in ln.upper():\n",
        "                m = re.search(r'([0-9\\.,]+)', ln)\n",
        "                if m:\n",
        "                    return normalize_money(m.group(1))\n",
        "        return None\n",
        "\n",
        "    total = find_value_after('TOTAL')\n",
        "    subtotal = find_value_after('SUBTOTAL')\n",
        "\n",
        "    iva_porcentaje = None\n",
        "    m = re.search(r'IVA\\s*(\\d{1,2})\\s*%|IVA\\s*%\\s*(\\d{1,2})', text.upper())\n",
        "    if m:\n",
        "        iva_porcentaje = int([g for g in m.groups() if g][0])\n",
        "    iva_valor = find_value_after('IVA')\n",
        "\n",
        "    razon = None\n",
        "    # Heurística: línea con RAZON o CLIENTE/PROVEEDOR cercana a NIT\n",
        "    for ln in lines:\n",
        "        up = ln.upper()\n",
        "        if 'RAZON' in up or 'PROVEEDOR' in up or 'CLIENTE' in up:\n",
        "            if len(ln.split())>=2:\n",
        "                razon = ln\n",
        "                break\n",
        "\n",
        "    return {\n",
        "        'fecha': fecha,\n",
        "        'nit': nit,\n",
        "        'razon_social': razon,\n",
        "        'subtotal': subtotal,\n",
        "        'iva_porcentaje': iva_porcentaje,\n",
        "        'iva_valor': iva_valor,\n",
        "        'total': total\n",
        "    }\n",
        "\n",
        "# Evaluación en test\n",
        "\n",
        "FIELDS = ['fecha','nit','razon_social','subtotal','iva_porcentaje','iva_valor','total']\n",
        "\n",
        "def validate_accounting(fields):\n",
        "    subtotal = normalize_money(fields.get('subtotal'))\n",
        "    iva_val = normalize_money(fields.get('iva_valor'))\n",
        "    total = normalize_money(fields.get('total'))\n",
        "    if None in [subtotal, iva_val, total]:\n",
        "        return False\n",
        "    return abs(subtotal + iva_val - total) < 1.01\n",
        "\n",
        "\n",
        "def evaluate_method(name, predictor):\n",
        "    test_ids = load_ids('test') if (SPLITS/'test.txt').exists() else []\n",
        "    rows = []\n",
        "    latencies = []\n",
        "    for doc_id in test_ids:\n",
        "        gt = read_gt(doc_id)\n",
        "        t0 = time.time()\n",
        "        pred = predictor(doc_id)\n",
        "        latencies.append(time.time()-t0)\n",
        "        row = {'doc_id': doc_id}\n",
        "        for f in FIELDS:\n",
        "            gtv = gt.get('campos',{}).get(f)\n",
        "            pv = pred.get(f)\n",
        "            if f in ['subtotal','iva_valor','total']:\n",
        "                gtvn = normalize_money(gtv)\n",
        "                pvnn = normalize_money(pv)\n",
        "                row[f'EM_{f}'] = 1.0 if (gtvn is not None and pvnn is not None and abs(gtvn - pvnn) < 1e-2) else 0.0\n",
        "            else:\n",
        "                row[f'EM_{f}'] = exact_match(gtv, pv)\n",
        "        row['accounting_ok'] = validate_accounting(pred)\n",
        "        rows.append(row)\n",
        "    df = pd.DataFrame(rows)\n",
        "    em_cols = [c for c in df.columns if c.startswith('EM_')]\n",
        "    em_macro = df[em_cols].mean().mean() if not df.empty else 0.0\n",
        "    acc_pct = df['accounting_ok'].mean() if not df.empty else 0.0\n",
        "    lat_mean = float(np.mean(latencies)) if latencies else 0.0\n",
        "    return df, {'name': name, 'em_macro': em_macro, 'accounting_pct': acc_pct, 'latency_s': lat_mean}\n",
        "\n",
        "# Definir predictores de cada método (aquí baseline y placeholders para Donut/LayoutLMv3)\n",
        "\n",
        "def predict_paddle_rules(doc_id):\n",
        "    return heuristic_extract(doc_id)\n",
        "\n",
        "def predict_donut(doc_id):\n",
        "    # TODO: cargar DONUT y parsear JSON; placeholder usa baseline\n",
        "    return heuristic_extract(doc_id)\n",
        "\n",
        "def predict_layoutlmv3(doc_id):\n",
        "    # TODO: cargar LayoutLMv3 y etiquetar tokens; placeholder usa baseline\n",
        "    return heuristic_extract(doc_id)\n",
        "\n",
        "res_tables = {}\n",
        "summary_rows = []\n",
        "for name, pred in [('Paddle+Reglas','paddle'), ('Donut','donut'), ('LayoutLMv3','layout')]:\n",
        "    func = predict_paddle_rules if pred=='paddle' else predict_donut if pred=='donut' else predict_layoutlmv3\n",
        "    df, info = evaluate_method(name, func)\n",
        "    res_tables[name] = df\n",
        "    summary_rows.append(info)\n",
        "\n",
        "summary = pd.DataFrame(summary_rows)\n",
        "# tamaños y facilidad despliegue (estimados)\n",
        "size_map = {'Paddle+Reglas': 50, 'Donut': 400, 'LayoutLMv3': 450}  # MB aprox\n",
        "deploy_map = {'Paddle+Reglas': 5, 'Donut': 2, 'LayoutLMv3': 2}\n",
        "summary['size_mb'] = summary['name'].map(size_map)\n",
        "summary['deploy_ease'] = summary['name'].map(deploy_map)\n",
        "\n",
        "# Calcular score final\n",
        "from scipy.stats import zscore\n",
        "summary['lat_z'] = zscore(summary['latency_s']) if len(summary)>1 else 0\n",
        "summary['size_z'] = zscore(summary['size_mb']) if len(summary)>1 else 0\n",
        "summary['score'] = 0.6*summary['em_macro'] + 0.2*summary['accounting_pct'] - 0.1*summary['lat_z'] - 0.1*summary['size_z']\n",
        "\n",
        "# Ganador\n",
        "best = summary.sort_values('score', ascending=False).iloc[0]\n",
        "# Empate → mayor deploy_ease\n",
        "tied = summary[summary['score']==best['score']]\n",
        "if len(tied)>1:\n",
        "    best = tied.sort_values('deploy_ease', ascending=False).iloc[0]\n",
        "\n",
        "summary.to_csv(REPORTS/'model_comparison.csv', index=False)\n",
        "\n",
        "# PDF\n",
        "with PdfPages(REPORTS/'model_comparison.pdf') as pdf:\n",
        "    fig, ax = plt.subplots(figsize=(6,4))\n",
        "    ax.bar(summary['name'], summary['em_macro'], color='steelblue')\n",
        "    ax.set_title('Exact Match Macro por Método')\n",
        "    ax.set_ylim(0,1)\n",
        "    plt.tight_layout(); pdf.savefig(fig); plt.close(fig)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6,4))\n",
        "    ax.bar(summary['name'], summary['accounting_pct'], color='seagreen')\n",
        "    ax.set_title('% Validación Contable')\n",
        "    ax.set_ylim(0,1)\n",
        "    plt.tight_layout(); pdf.savefig(fig); plt.close(fig)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6,4))\n",
        "    ax.bar(summary['name'], summary['score'], color='indianred')\n",
        "    ax.set_title('Score final')\n",
        "    plt.tight_layout(); pdf.savefig(fig); plt.close(fig)\n",
        "\n",
        "best_info = {'best_model': best['name'], 'metrics': best.to_dict()}\n",
        "with open(REPORTS/'best_model.json','w',encoding='utf-8') as f:\n",
        "    json.dump(best_info, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "summary, best_info\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
